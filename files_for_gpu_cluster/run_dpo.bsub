#!/bin/bash -l
## Scheduler parameters ##
  
#BSUB -J dpo_qwen72b_train             # job name
#BSUB -o outputs/0426/qwen72b_dpo_inf_b2.%J.stdout   # optional: have output written to specific file
#BSUB -e outputs/0426/qwen72b_dpo_inf_b2.%J.stderr   # optional: have errors written to specific file
#BSUB -q batch_h100               # optional: use highend nodes w/ Volta GPUs (default: Geforce GPUs)
#BSUB -W 05:00                         # fill in desired wallclock time [hours,]minutes (hours are optional)
#BSUB -n 4                         # min CPU cores,max CPU cores (max cores is optional)
#BSUB -M 16G                       # fill in required amount of memory per CPU core(in Mbyte)
# #BSUB -R "span[hosts=1]"          # optional: run on single host (if using more than 1 CPU core)
# #BSUB -R "span[ptile=28]"         # optional: fill in to specify cores per node (max 28-40 depending on node type)
# #BSUB -P myProject                # optional: fill in cluster project
#BSUB -gpu "num=1"
  
# Here comes your code
HF_ACCESS_TOKEN="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"

module load conda proxy4server-access
source /fs/applications/p4s-access/2.0/ActivateP4S.sh -a
conda activate llava
# conda activate lta
export HF_HOME="/fs/scratch/rb_bd_dlp_rng-dl01_cr_ROB_employees/students/pau1rng/huggingface"
huggingface-cli login --token "$HF_ACCESS_TOKEN"

cd ~/projects/dpo_scripts
# pip install git+https://github.com/huggingface/trl.git
wandb login 41bd6a3035f10a84948f54cf7ac6add18850c8c5
# python qwen_infer.py
accelerate launch dpo_test_qwen.py
# python dpo_test_qwen.py